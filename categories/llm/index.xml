<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Llm on ExitCode0</title><link>https://exitcode0.net/categories/llm/</link><description>Recent content in Llm on ExitCode0</description><generator>Hugo -- 0.140.2</generator><language>en-gb</language><lastBuildDate>Sun, 28 Jul 2024 07:00:00 +0100</lastBuildDate><atom:link href="https://exitcode0.net/categories/llm/index.xml" rel="self" type="application/rss+xml"/><item><title>Testing Llama3.1 (8B) With LM Studio</title><link>https://exitcode0.net/posts/testing-llama3_1-with-gpt4all/</link><pubDate>Sun, 28 Jul 2024 07:00:00 +0100</pubDate><guid>https://exitcode0.net/posts/testing-llama3_1-with-gpt4all/</guid><description>Taking a look at the the latest open source llama 3.1 model after its July 2024 release. Testing its performance and accuracy with GPT4ALL.</description></item><item><title>Testing Llama3 With LM Studio</title><link>https://exitcode0.net/posts/testing-llama3-with-lmstudio/</link><pubDate>Fri, 19 Apr 2024 07:00:00 +0100</pubDate><guid>https://exitcode0.net/posts/testing-llama3-with-lmstudio/</guid><description>Taking a look at the the latest open source llama 3 model after its April 2024 release. Testing its performance and accuracy with LM Studio.</description></item></channel></rss>