<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Llama on ExitCode0</title><link>https://exitcode0.net/tags/llama/</link><description>Recent content in Llama on ExitCode0</description><generator>Hugo -- 0.134.3</generator><language>en-gb</language><lastBuildDate>Sun, 28 Jul 2024 07:00:00 +0100</lastBuildDate><atom:link href="https://exitcode0.net/tags/llama/index.xml" rel="self" type="application/rss+xml"/><item><title>Testing Llama3.1 (8B) With LM Studio</title><link>https://exitcode0.net/posts/testing-llama3_1-with-gpt4all/</link><pubDate>Sun, 28 Jul 2024 07:00:00 +0100</pubDate><guid>https://exitcode0.net/posts/testing-llama3_1-with-gpt4all/</guid><description>Taking a look at the the latest open source llama 3.1 model after its July 2024 release. Testing its performance and accuracy with GPT4ALL.</description></item></channel></rss>