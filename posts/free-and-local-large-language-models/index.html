<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Free and Local Large Language Models | ExitCode0</title>
<meta name="keywords" content="LLM, AI, huggingface, LMstudio">
<meta name="description" content="TLDR: A brief overview of large language models (LLMs) and a guide on using LMstudio and VSCode Continue to replcate github copilot, without the subscription fee.
LLMs: The Next Revolution in Computing? Large Language Models (LLMs) have been making waves in the tech industry lately. These neural network models can understand and generate human-like text, making them a game-changer for many applications and industries, from content creation to customer support. In this post, we will explore what LLMs are, how you can set up and use them with LMstudio, how to integrate LMstudio with VS Code, and conclude with why LLMs are not AGI but can still be incredibly useful for professionals.">
<meta name="author" content="Tom C">
<link rel="canonical" href="http://localhost:1313/posts/free-and-local-large-language-models/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.4599eadb9eb2ad3d0a8d6827b41a8fda8f2f4af226b63466c09c5fddbc8706b7.css" integrity="sha256-RZnq256yrT0KjWgntBqP2o8vSvImtjRmwJxf3byHBrc=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/posts/free-and-local-large-language-models/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7745507566538945"
    crossorigin="anonymous"></script>
<script data-name="BMC-Widget" data-cfasync="false" src="https://cdnjs.buymeacoffee.com/1.0.0/widget.prod.min.js"
    data-id="exit" data-description="Support me on Buy me a coffee!" data-message="Buy me a coffee"
    data-color="#FF813F" data-position="Right" data-x_margin="18" data-y_margin="165"></script>


<script async src="https://www.googletagmanager.com/gtag/js?id=G-EDE9MPZR9T"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-EDE9MPZR9T', { 'anonymize_ip': false });
}
</script>
<meta property="og:title" content="Free and Local Large Language Models" />
<meta property="og:description" content="TLDR: A brief overview of large language models (LLMs) and a guide on using LMstudio and VSCode Continue to replcate github copilot, without the subscription fee.
LLMs: The Next Revolution in Computing? Large Language Models (LLMs) have been making waves in the tech industry lately. These neural network models can understand and generate human-like text, making them a game-changer for many applications and industries, from content creation to customer support. In this post, we will explore what LLMs are, how you can set up and use them with LMstudio, how to integrate LMstudio with VS Code, and conclude with why LLMs are not AGI but can still be incredibly useful for professionals." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/posts/free-and-local-large-language-models/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-03-13T06:10:33+00:00" />
<meta property="article:modified_time" content="2024-03-13T06:10:33+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Free and Local Large Language Models"/>
<meta name="twitter:description" content="TLDR: A brief overview of large language models (LLMs) and a guide on using LMstudio and VSCode Continue to replcate github copilot, without the subscription fee.
LLMs: The Next Revolution in Computing? Large Language Models (LLMs) have been making waves in the tech industry lately. These neural network models can understand and generate human-like text, making them a game-changer for many applications and industries, from content creation to customer support. In this post, we will explore what LLMs are, how you can set up and use them with LMstudio, how to integrate LMstudio with VS Code, and conclude with why LLMs are not AGI but can still be incredibly useful for professionals."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "http://localhost:1313/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Free and Local Large Language Models",
      "item": "http://localhost:1313/posts/free-and-local-large-language-models/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Free and Local Large Language Models",
  "name": "Free and Local Large Language Models",
  "description": "TLDR: A brief overview of large language models (LLMs) and a guide on using LMstudio and VSCode Continue to replcate github copilot, without the subscription fee.\nLLMs: The Next Revolution in Computing? Large Language Models (LLMs) have been making waves in the tech industry lately. These neural network models can understand and generate human-like text, making them a game-changer for many applications and industries, from content creation to customer support. In this post, we will explore what LLMs are, how you can set up and use them with LMstudio, how to integrate LMstudio with VS Code, and conclude with why LLMs are not AGI but can still be incredibly useful for professionals.",
  "keywords": [
    "LLM", "AI", "huggingface", "LMstudio"
  ],
  "articleBody": "TLDR: A brief overview of large language models (LLMs) and a guide on using LMstudio and VSCode Continue to replcate github copilot, without the subscription fee.\nLLMs: The Next Revolution in Computing? Large Language Models (LLMs) have been making waves in the tech industry lately. These neural network models can understand and generate human-like text, making them a game-changer for many applications and industries, from content creation to customer support. In this post, we will explore what LLMs are, how you can set up and use them with LMstudio, how to integrate LMstudio with VS Code, and conclude with why LLMs are not AGI but can still be incredibly useful for professionals. We will also provide examples of popular large language models like llama2, GPT-3.5, and Gemini, and discuss their performance.\nWhat is a Large Language Model (LLM)? [Insert relevant image here]\nA LLM is a type of neural network model that has been trained on vast amounts of text data. These models can generate human-like responses to prompts and understand the context of the text they are presented with. Unlike traditional search algorithms, which match keywords in a query with documents containing those words, LLMs can understand the meaning behind the words and make connections between them.\n[Insert visualization here]\nLLMs work by processing sequential data through a series of layers that transform the input into a meaningful output. The model uses an attention mechanism to focus on specific parts of the input sequence and generate a response based on that focus. This allows LLMs to understand the relationships between words in a sentence and generate responses that are contextually relevant.\n[Insert image of LLM architecture]\nPopular LLM Architectures: BERT, GPT-3, and RoBERT BERT (Bidirectional Encoder Representations from Transformers) - Developed by Google AI, BERT is a state-of-the-art NLP (Natural Language Processing) model that uses a bidirectional transformer architecture to better understand the context of words in a sentence. Unlike traditional NLP models that only process text in one direction (from left to right), BERT can understand the meaning of words based on their position within a sentence, regardless of whether they appear at the beginning, middle, or end. Use Cases: BERT is commonly used for tasks such as question answering, sentiment analysis, and information retrieval. Its bidirectional architecture makes it particularly effective for understanding the relationships between words in a sentence, which can be helpful for tasks like summarization, where context is critical. [Insert relevant image of BERT model here]\nGPT-3 (Generative Pretrained Transformer 3) - Developed by OpenAI, GPT-3 is a large-scale LLM with over 175 billion parameters that has been trained on a vast corpus of text data. This model can generate human-like text based on provided context and can be fine-tuned for specific tasks using a relatively small amount of additional data. Use Cases: GPT-3 is commonly used for tasks such as content creation, summarization, and translation. Its ability to understand context and generate coherent responses makes it particularly useful for tasks that require creative or imaginative output, where human-like response generation is critical. [Insert relevant image of GPT-3 model here]\nRoBERT (Robustly Optimized BERT Pretraining Approach) - Developed by Facebook AI, RoBERT is a variant of the BERT model that uses a different pretraining approach to improve its performance on downstream tasks like question answering and sentiment analysis. This model has shown impressive results on many NLP benchmarks and is commonly used in industrial-scale applications where fast inference times are critical. Use Cases: RoBERT is commonly used for tasks such as document classification, information retrieval, and summarization. Its improved performance on downstream tasks makes it a popular choice for production environments where speed and accuracy are essential. [Insert relevant image of RoBERT model here]\nSetting Up and Using LLMs with LMstudio [Insert screenshot of LMstudio interface here]\nLMstudio is a desktop app developed by Deepseek, which makes it easy to create, train, and use LLMs. Here’s how you can set up and use LLMs with LMstudio:\nDownload and install LMstudio from the official website (https://www.lmstudio.ai/) Create a new project by clicking on “New Project” in the main menu. Give your project a name and choose the type of model you want to create (e.g., BERT, GPT-3, or RoBERT). Once you have created your project, you can start training your model by importing your data and configuring the training settings. LMstudio supports multiple datasets, including Wikipedia, Common Crawl, and BooksCorpus. After training your model, you can use it to generate responses to prompts or to perform other language-related tasks. To do this, click on “New Session” in the main menu and select your trained LLM from the list of available models. Enter your prompt into the text box provided, and LMstudio will generate a response based on that context. You can fine-tune the model’s behavior by adjusting various settings, such as temperature and top k sampling rate. [Insert screenshot of VS Code Continue plugin interface here]\nIntegrating LMstudio with VS Code Continue Plugin [Insert relevant image of VS Code plugin installation process here]\nLMstudio is great for creating and using LLMs, but it can be limiting when working in other applications, like VS Code. That’s where the VS Code Continue plugin comes in. This plugin allows you to use your trained LLMs directly within VS Code by integrating LMstudio with the editor.\nHere’s how you can set up and use the VS Code Continue plugin:\nInstall the VS Code Continue plugin from the Marketplace (https://marketplace.visualstudio.com/items?itemName=Deepseek.continue) Restart VS Code to ensure that the plugin is loaded properly. Create a new JavaScript file in your project and add the following code: const { continue_ } = require(\"@deepseek/continue\"); const model = \"my-model\"; // replace 'my-model' with the name of your trained LLM const prompt = \"What is the meaning of life?\"; const response = await continue_(model, prompt); console.log(response); This code imports the continue_ function from the @deepseek/continue module and uses it to generate a response based on your trained LLM and the provided prompt. The response is then printed to the console output. 4. Save the file and run it by pressing Ctrl + Shift + N (Windows, Linux) or Command + Shift + N (Mac). You should see the generated response in the console output.\nLLMs vs AGI: What’s the Difference? While LLMs are incredibly powerful tools for generating human-like text and understanding context, they are not AGI (Artificial General Intelligence). AGI is a theoretical concept that describes an AI system’s ability to learn and reason like humans. While LLMs can understand the context of text and generate responses based on that context, they lack many of the cognitive abilities that make human intelligence so powerful.\nFor example, LLMs cannot perform tasks that require common sense or reasoning, as they do not have a complete understanding of the world around them. They also struggle with complex syntax and grammar, making it challenging for them to generate responses that are completely accurate and grammatically correct.\nDespite these limitations, LLMs can still be incredibly useful tools for high skill professionals in fields like law, medicine, and finance. By generating responses based on provided context, LLMs can save time and resources by automating repetitive or low-level tasks. They can also help professionals to focus on more complex and higher-level tasks, where their expertise and judgment are needed.\nIn conclusion, LLMs represent the next revolution in computing, with the potential to transform many industries and applications. By making it easy to create, train, and use LLMs, tools like LMstudio and VS Code Continue plugin are helping to make this technology accessible to more people. While LLMs may not be AGI, they are still incredibly useful tools for high skill professionals, and we can expect to see even more exciting developments in this field in the coming years.\n",
  "wordCount" : "1296",
  "inLanguage": "en",
  "datePublished": "2024-03-13T06:10:33Z",
  "dateModified": "2024-03-13T06:10:33Z",
  "author":{
    "@type": "Person",
    "name": "Tom C"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:1313/posts/free-and-local-large-language-models/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "ExitCode0",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:1313/favicon.ico"
    }
  }
}
</script>
</head>

<body class=" dark" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="ExitCode0 (Alt + H)">ExitCode0</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://datasolace.com/" title="DataSolace">
                    <span>DataSolace</span>&nbsp;
                    <svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round"
                        stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12">
                        <path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"></path>
                        <path d="M15 3h6v6"></path>
                        <path d="M10 14L21 3"></path>
                    </svg>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/categories/" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/privacy/" title="Privacy">
                    <span>Privacy</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://localhost:1313/">Home</a>&nbsp;»&nbsp;<a href="http://localhost:1313/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      Free and Local Large Language Models
      <span class="entry-hint" title="Draft">
        <svg xmlns="http://www.w3.org/2000/svg" height="35" viewBox="0 -960 960 960" fill="currentColor">
          <path
            d="M160-410v-60h300v60H160Zm0-165v-60h470v60H160Zm0-165v-60h470v60H160Zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22q0 11-4.5 22.5T862.09-380L643-160H520Zm300-263-37-37 37 37ZM580-220h38l121-122-18-19-19-18-122 121v38Zm141-141-19-18 37 37-18-19Z" />
        </svg>
      </span>
    </h1>
    <div class="post-meta"><span title='2024-03-13 06:10:33 +0000 UTC'>March 13, 2024</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;Tom C

</div>
  </header> <div class="toc">
    <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#llms-the-next-revolution-in-computing" aria-label="LLMs: The Next Revolution in Computing?">LLMs: The Next Revolution in Computing?</a></li>
                <li>
                    <a href="#what-is-a-large-language-model-llm" aria-label="What is a Large Language Model (LLM)?">What is a Large Language Model (LLM)?</a></li>
                <li>
                    <a href="#popular-llm-architectures-bert-gpt-3-and-robert" aria-label="Popular LLM Architectures: BERT, GPT-3, and RoBERT">Popular LLM Architectures: BERT, GPT-3, and RoBERT</a></li>
                <li>
                    <a href="#setting-up-and-using-llms-with-lmstudio" aria-label="Setting Up and Using LLMs with LMstudio">Setting Up and Using LLMs with LMstudio</a></li>
                <li>
                    <a href="#integrating-lmstudio-with-vs-code-continue-plugin" aria-label="Integrating LMstudio with VS Code Continue Plugin">Integrating LMstudio with VS Code Continue Plugin</a></li>
                <li>
                    <a href="#llms-vs-agi-whats-the-difference" aria-label="LLMs vs AGI: What&rsquo;s the Difference?">LLMs vs AGI: What&rsquo;s the Difference?</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p><strong>TLDR:</strong> A brief overview of large language models (LLMs) and a guide on using LMstudio and VSCode Continue to replcate github copilot, without the subscription fee.</p>
<h2 id="llms-the-next-revolution-in-computing">LLMs: The Next Revolution in Computing?<a hidden class="anchor" aria-hidden="true" href="#llms-the-next-revolution-in-computing">#</a></h2>
<p>Large Language Models (LLMs) have been making waves in the tech industry lately. These neural network models can understand and generate human-like text, making them a game-changer for many applications and industries, from content creation to customer support. In this post, we will explore what LLMs are, how you can set up and use them with LMstudio, how to integrate LMstudio with VS Code, and conclude with why LLMs are not AGI but can still be incredibly useful for professionals. We will also provide examples of popular large language models like llama2, GPT-3.5, and Gemini, and discuss their performance.</p>
<h2 id="what-is-a-large-language-model-llm">What is a Large Language Model (LLM)?<a hidden class="anchor" aria-hidden="true" href="#what-is-a-large-language-model-llm">#</a></h2>
<p>[Insert relevant image here]</p>
<p>A LLM is a type of neural network model that has been trained on vast amounts of text data. These models can generate human-like responses to prompts and understand the context of the text they are presented with. Unlike traditional search algorithms, which match keywords in a query with documents containing those words, LLMs can understand the meaning behind the words and make connections between them.</p>
<p>[Insert visualization here]</p>
<p>LLMs work by processing sequential data through a series of layers that transform the input into a meaningful output. The model uses an attention mechanism to focus on specific parts of the input sequence and generate a response based on that focus. This allows LLMs to understand the relationships between words in a sentence and generate responses that are contextually relevant.</p>
<p>[Insert image of LLM architecture]</p>
<h2 id="popular-llm-architectures-bert-gpt-3-and-robert">Popular LLM Architectures: BERT, GPT-3, and RoBERT<a hidden class="anchor" aria-hidden="true" href="#popular-llm-architectures-bert-gpt-3-and-robert">#</a></h2>
<p>BERT (Bidirectional Encoder Representations from Transformers) - Developed by Google AI, BERT is a state-of-the-art NLP (Natural Language Processing) model that uses a bidirectional transformer architecture to better understand the context of words in a sentence. Unlike traditional NLP models that only process text in one direction (from left to right), BERT can understand the meaning of words based on their position within a sentence, regardless of whether they appear at the beginning, middle, or end. Use Cases: BERT is commonly used for tasks such as question answering, sentiment analysis, and information retrieval. Its bidirectional architecture makes it particularly effective for understanding the relationships between words in a sentence, which can be helpful for tasks like summarization, where context is critical. [Insert relevant image of BERT model here]</p>
<p>GPT-3 (Generative Pretrained Transformer 3) - Developed by OpenAI, GPT-3 is a large-scale LLM with over 175 billion parameters that has been trained on a vast corpus of text data. This model can generate human-like text based on provided context and can be fine-tuned for specific tasks using a relatively small amount of additional data. Use Cases: GPT-3 is commonly used for tasks such as content creation, summarization, and translation. Its ability to understand context and generate coherent responses makes it particularly useful for tasks that require creative or imaginative output, where human-like response generation is critical. [Insert relevant image of GPT-3 model here]</p>
<p>RoBERT (Robustly Optimized BERT Pretraining Approach) - Developed by Facebook AI, RoBERT is a variant of the BERT model that uses a different pretraining approach to improve its performance on downstream tasks like question answering and sentiment analysis. This model has shown impressive results on many NLP benchmarks and is commonly used in industrial-scale applications where fast inference times are critical. Use Cases: RoBERT is commonly used for tasks such as document classification, information retrieval, and summarization. Its improved performance on downstream tasks makes it a popular choice for production environments where speed and accuracy are essential. [Insert relevant image of RoBERT model here]</p>
<h2 id="setting-up-and-using-llms-with-lmstudio">Setting Up and Using LLMs with LMstudio<a hidden class="anchor" aria-hidden="true" href="#setting-up-and-using-llms-with-lmstudio">#</a></h2>
<p>[Insert screenshot of LMstudio interface here]</p>
<p>LMstudio is a desktop app developed by Deepseek, which makes it easy to create, train, and use LLMs. Here&rsquo;s how you can set up and use LLMs with LMstudio:</p>
<ol>
<li>Download and install LMstudio from the official website (<a href="https://www.lmstudio.ai/">https://www.lmstudio.ai/</a>)</li>
<li>Create a new project by clicking on &ldquo;New Project&rdquo; in the main menu. Give your project a name and choose the type of model you want to create (e.g., BERT, GPT-3, or RoBERT).</li>
<li>Once you have created your project, you can start training your model by importing your data and configuring the training settings. LMstudio supports multiple datasets, including Wikipedia, Common Crawl, and BooksCorpus.</li>
<li>After training your model, you can use it to generate responses to prompts or to perform other language-related tasks. To do this, click on &ldquo;New Session&rdquo; in the main menu and select your trained LLM from the list of available models.</li>
<li>Enter your prompt into the text box provided, and LMstudio will generate a response based on that context. You can fine-tune the model&rsquo;s behavior by adjusting various settings, such as temperature and top k sampling rate.</li>
</ol>
<p>[Insert screenshot of VS Code Continue plugin interface here]</p>
<h2 id="integrating-lmstudio-with-vs-code-continue-plugin">Integrating LMstudio with VS Code Continue Plugin<a hidden class="anchor" aria-hidden="true" href="#integrating-lmstudio-with-vs-code-continue-plugin">#</a></h2>
<p>[Insert relevant image of VS Code plugin installation process here]</p>
<p>LMstudio is great for creating and using LLMs, but it can be limiting when working in other applications, like VS Code. That&rsquo;s where the VS Code Continue plugin comes in. This plugin allows you to use your trained LLMs directly within VS Code by integrating LMstudio with the editor.</p>
<p>Here&rsquo;s how you can set up and use the VS Code Continue plugin:</p>
<ol>
<li>Install the VS Code Continue plugin from the Marketplace (<a href="https://marketplace.visualstudio.com/items?itemName=Deepseek.continue">https://marketplace.visualstudio.com/items?itemName=Deepseek.continue</a>)</li>
<li>Restart VS Code to ensure that the plugin is loaded properly.</li>
<li>Create a new JavaScript file in your project and add the following code:</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-javascript" data-lang="javascript"><span style="display:flex;"><span><span style="color:#66d9ef">const</span> { <span style="color:#a6e22e">continue_</span> } <span style="color:#f92672">=</span> <span style="color:#a6e22e">require</span>(<span style="color:#e6db74">&#34;@deepseek/continue&#34;</span>);
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">const</span> <span style="color:#a6e22e">model</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;my-model&#34;</span>; <span style="color:#75715e">// replace &#39;my-model&#39; with the name of your trained LLM
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">const</span> <span style="color:#a6e22e">prompt</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;What is the meaning of life?&#34;</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">const</span> <span style="color:#a6e22e">response</span> <span style="color:#f92672">=</span> <span style="color:#66d9ef">await</span> <span style="color:#a6e22e">continue_</span>(<span style="color:#a6e22e">model</span>, <span style="color:#a6e22e">prompt</span>);
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">console</span>.<span style="color:#a6e22e">log</span>(<span style="color:#a6e22e">response</span>);
</span></span></code></pre></div><p>This code imports the <code>continue_</code> function from the <code>@deepseek/continue</code> module and uses it to generate a response based on your trained LLM and the provided prompt. The response is then printed to the console output. 4. Save the file and run it by pressing Ctrl + Shift + N (Windows, Linux) or Command + Shift + N (Mac). You should see the generated response in the console output.</p>
<h2 id="llms-vs-agi-whats-the-difference">LLMs vs AGI: What&rsquo;s the Difference?<a hidden class="anchor" aria-hidden="true" href="#llms-vs-agi-whats-the-difference">#</a></h2>
<p>While LLMs are incredibly powerful tools for generating human-like text and understanding context, they are not AGI (Artificial General Intelligence). AGI is a theoretical concept that describes an AI system&rsquo;s ability to learn and reason like humans. While LLMs can understand the context of text and generate responses based on that context, they lack many of the cognitive abilities that make human intelligence so powerful.</p>
<p>For example, LLMs cannot perform tasks that require common sense or reasoning, as they do not have a complete understanding of the world around them. They also struggle with complex syntax and grammar, making it challenging for them to generate responses that are completely accurate and grammatically correct.</p>
<p>Despite these limitations, LLMs can still be incredibly useful tools for high skill professionals in fields like law, medicine, and finance. By generating responses based on provided context, LLMs can save time and resources by automating repetitive or low-level tasks. They can also help professionals to focus on more complex and higher-level tasks, where their expertise and judgment are needed.</p>
<p>In conclusion, LLMs represent the next revolution in computing, with the potential to transform many industries and applications. By making it easy to create, train, and use LLMs, tools like LMstudio and VS Code Continue plugin are helping to make this technology accessible to more people. While LLMs may not be AGI, they are still incredibly useful tools for high skill professionals, and we can expect to see even more exciting developments in this field in the coming years.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:1313/tags/llm/">LLM</a></li>
      <li><a href="http://localhost:1313/tags/ai/">AI</a></li>
      <li><a href="http://localhost:1313/tags/huggingface/">Huggingface</a></li>
      <li><a href="http://localhost:1313/tags/lmstudio/">LMstudio</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="http://localhost:1313/posts/writing-blog-posts-with-local-llms/">
    <span class="title">« Prev</span>
    <br>
    <span>Writing Blog Posts With Local LLMs</span>
  </a>
  <a class="next" href="http://localhost:1313/posts/homeassistant-tls-with-tailscale-traefik/">
    <span class="title">Next »</span>
    <br>
    <span>Home Assistant HTTPS Certificates with Tailscale, Traefik and CoreDNS</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:1313/">ExitCode0</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
